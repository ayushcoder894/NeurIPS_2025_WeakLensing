{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cca94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive dataset summary\n",
    "summary_file = os.path.join(data_dir, 'dataset_summary.txt')\n",
    "\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"NeurIPS 2025 WEAK LENSING CHALLENGE - DATASET SUMMARY\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"DATASET CONFIGURATION\\n\")\n",
    "    f.write(\"-\" * 70 + \"\\n\")\n",
    "    f.write(f\"Expected Image Dimensions: {IMAGE_HEIGHT} × {IMAGE_WIDTH} pixels\\n\")\n",
    "    f.write(f\"Resolution: {RESOLUTION_ARCMIN} arcmin/pixel\\n\")\n",
    "    f.write(f\"Number of Cosmological Models: {NUM_COSMOLOGICAL_MODELS}\\n\")\n",
    "    f.write(f\"Field: Convergence map of redshift BIN 2 of WIDE12H subfield\\n\\n\")\n",
    "    \n",
    "    f.write(\"FILES LOADED\\n\")\n",
    "    f.write(\"-\" * 70 + \"\\n\")\n",
    "    for name, path in files_to_check.items():\n",
    "        exists = os.path.exists(path)\n",
    "        f.write(f\"{name}: {'Found' if exists else 'Not found'}\\n\")\n",
    "        if exists:\n",
    "            size_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "            f.write(f\"  Size: {size_mb:.2f} MB\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    if labels is not None:\n",
    "        f.write(\"LABELS\\n\")\n",
    "        f.write(\"-\" * 70 + \"\\n\")\n",
    "        f.write(f\"Shape: {labels.shape}\\n\")\n",
    "        f.write(f\"Data type: {labels.dtype}\\n\")\n",
    "        if len(labels.shape) == 2:\n",
    "            omega_m = labels[:, 0]\n",
    "            s_8 = labels[:, 1]\n",
    "            f.write(f\"Number of samples: {labels.shape[0]}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Ω_m Statistics:\\n\")\n",
    "            f.write(f\"  Mean:   {np.mean(omega_m):.6f}\\n\")\n",
    "            f.write(f\"  Std:    {np.std(omega_m):.6f}\\n\")\n",
    "            f.write(f\"  Min:    {np.min(omega_m):.6f}\\n\")\n",
    "            f.write(f\"  Max:    {np.max(omega_m):.6f}\\n\")\n",
    "            f.write(f\"  Median: {np.median(omega_m):.6f}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"S_8 Statistics:\\n\")\n",
    "            f.write(f\"  Mean:   {np.mean(s_8):.6f}\\n\")\n",
    "            f.write(f\"  Std:    {np.std(s_8):.6f}\\n\")\n",
    "            f.write(f\"  Min:    {np.min(s_8):.6f}\\n\")\n",
    "            f.write(f\"  Max:    {np.max(s_8):.6f}\\n\")\n",
    "            f.write(f\"  Median: {np.median(s_8):.6f}\\n\\n\")\n",
    "            \n",
    "            correlation = np.corrcoef(omega_m, s_8)[0, 1]\n",
    "            f.write(f\"Correlation (Ω_m, S_8): {correlation:.6f}\\n\\n\")\n",
    "    \n",
    "    if kappa is not None:\n",
    "        f.write(\"CONVERGENCE MAPS (TRAINING)\\n\")\n",
    "        f.write(\"-\" * 70 + \"\\n\")\n",
    "        f.write(f\"Shape: {kappa.shape}\\n\")\n",
    "        f.write(f\"Data type: {kappa.dtype}\\n\")\n",
    "        f.write(f\"Memory usage: {kappa.nbytes / (1024**2):.2f} MB\\n\\n\")\n",
    "        f.write(f\"Global Statistics:\\n\")\n",
    "        f.write(f\"  Mean: {np.mean(kappa):.6f}\\n\")\n",
    "        f.write(f\"  Std:  {np.std(kappa):.6f}\\n\")\n",
    "        f.write(f\"  Min:  {np.min(kappa):.6f}\\n\")\n",
    "        f.write(f\"  Max:  {np.max(kappa):.6f}\\n\")\n",
    "        f.write(f\"  Contains NaN: {np.any(np.isnan(kappa))}\\n\")\n",
    "        f.write(f\"  Contains Inf: {np.any(np.isinf(kappa))}\\n\\n\")\n",
    "        \n",
    "        if len(kappa.shape) == 3:\n",
    "            sample_means = np.mean(kappa, axis=(1, 2))\n",
    "            sample_stds = np.std(kappa, axis=(1, 2))\n",
    "            f.write(f\"Per-Sample Statistics:\\n\")\n",
    "            f.write(f\"  Mean of means: {np.mean(sample_means):.6f}\\n\")\n",
    "            f.write(f\"  Mean of stds:  {np.mean(sample_stds):.6f}\\n\\n\")\n",
    "    \n",
    "    if kappa_test is not None:\n",
    "        f.write(\"CONVERGENCE MAPS (TEST - NOISY)\\n\")\n",
    "        f.write(\"-\" * 70 + \"\\n\")\n",
    "        f.write(f\"Shape: {kappa_test.shape}\\n\")\n",
    "        f.write(f\"Data type: {kappa_test.dtype}\\n\")\n",
    "        f.write(f\"Memory usage: {kappa_test.nbytes / (1024**2):.2f} MB\\n\\n\")\n",
    "        f.write(f\"Global Statistics:\\n\")\n",
    "        f.write(f\"  Mean: {np.mean(kappa_test):.6f}\\n\")\n",
    "        f.write(f\"  Std:  {np.std(kappa_test):.6f}\\n\")\n",
    "        f.write(f\"  Min:  {np.min(kappa_test):.6f}\\n\")\n",
    "        f.write(f\"  Max:  {np.max(kappa_test):.6f}\\n\\n\")\n",
    "    \n",
    "    if mask is not None:\n",
    "        f.write(\"MASK\\n\")\n",
    "        f.write(\"-\" * 70 + \"\\n\")\n",
    "        f.write(f\"Shape: {mask.shape}\\n\")\n",
    "        f.write(f\"Data type: {mask.dtype}\\n\")\n",
    "        f.write(f\"Unique values: {np.unique(mask)}\\n\")\n",
    "        if len(mask.shape) == 2:\n",
    "            valid_pixels = np.sum(mask > 0)\n",
    "            total_pixels = mask.size\n",
    "            f.write(f\"Valid pixels: {valid_pixels:,} ({100*valid_pixels/total_pixels:.2f}%)\\n\")\n",
    "            f.write(f\"Invalid pixels: {total_pixels - valid_pixels:,}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"Analysis completed successfully!\\n\")\n",
    "    f.write(f\"Generated: {np.datetime64('now')}\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"\\nDataset summary saved to: {summary_file}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a9b64e",
   "metadata": {},
   "source": [
    "## 10. Save Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mask is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"MASK ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if len(mask.shape) == 2:\n",
    "        # Single mask\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Visualize mask\n",
    "        im = axes[0].imshow(mask, cmap='gray', aspect='auto')\n",
    "        axes[0].set_title('Survey Mask', fontsize=13)\n",
    "        axes[0].set_xlabel('Width (pixels)')\n",
    "        axes[0].set_ylabel('Height (pixels)')\n",
    "        plt.colorbar(im, ax=axes[0], label='Mask Value')\n",
    "        \n",
    "        # Show masked region on a sample kappa map\n",
    "        if kappa is not None:\n",
    "            if len(kappa.shape) == 3:\n",
    "                sample_map = kappa[0].copy()\n",
    "            else:\n",
    "                sample_map = kappa.copy()\n",
    "            \n",
    "            masked_kappa = np.ma.masked_where(mask == 0, sample_map)\n",
    "            im2 = axes[1].imshow(masked_kappa, cmap='RdBu_r', aspect='auto')\n",
    "            axes[1].set_title('Convergence Map with Mask Applied', fontsize=13)\n",
    "            axes[1].set_xlabel('Width (pixels)')\n",
    "            axes[1].set_ylabel('Height (pixels)')\n",
    "            plt.colorbar(im2, ax=axes[1], label='κ (masked)')\n",
    "        \n",
    "        plt.suptitle('Survey Mask Visualization', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Mask coverage statistics\n",
    "        valid_fraction = np.sum(mask > 0) / mask.size\n",
    "        print(f\"\\nMask Coverage:\")\n",
    "        print(f\"  Valid pixels:   {np.sum(mask > 0):,}\")\n",
    "        print(f\"  Invalid pixels: {np.sum(mask == 0):,}\")\n",
    "        print(f\"  Total pixels:   {mask.size:,}\")\n",
    "        print(f\"  Valid fraction: {valid_fraction:.4%}\")\n",
    "        \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"No mask data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa4453",
   "metadata": {},
   "source": [
    "## 9. Visualize Mask Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a1a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kappa is not None and kappa_test is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING vs TEST SET COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check shapes\n",
    "    print(f\"\\nShape Comparison:\")\n",
    "    print(f\"  Training: {kappa.shape}\")\n",
    "    print(f\"  Test:     {kappa_test.shape}\")\n",
    "    \n",
    "    if len(kappa.shape) == 3 and len(kappa_test.shape) == 3:\n",
    "        print(f\"\\n  Training samples: {kappa.shape[0]}\")\n",
    "        print(f\"  Test samples:     {kappa_test.shape[0]}\")\n",
    "        \n",
    "        # Statistical comparison\n",
    "        train_mean = np.mean(kappa)\n",
    "        train_std = np.std(kappa)\n",
    "        test_mean = np.mean(kappa_test)\n",
    "        test_std = np.std(kappa_test)\n",
    "        \n",
    "        print(f\"\\nGlobal Statistics:\")\n",
    "        print(f\"  Training - Mean: {train_mean:.6f}, Std: {train_std:.6f}\")\n",
    "        print(f\"  Test     - Mean: {test_mean:.6f}, Std: {test_std:.6f}\")\n",
    "        print(f\"  Difference (Mean): {abs(train_mean - test_mean):.6f}\")\n",
    "        print(f\"  Difference (Std):  {abs(train_std - test_std):.6f}\")\n",
    "        \n",
    "        # Distribution comparison\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Histogram comparison\n",
    "        axes[0].hist(kappa.flatten(), bins=100, alpha=0.5, label='Training', \n",
    "                    density=True, edgecolor='none')\n",
    "        axes[0].hist(kappa_test.flatten(), bins=100, alpha=0.5, label='Test (Noisy)', \n",
    "                    density=True, edgecolor='none')\n",
    "        axes[0].set_xlabel('κ (Convergence Value)')\n",
    "        axes[0].set_ylabel('Density')\n",
    "        axes[0].set_title('Pixel Value Distribution Comparison')\n",
    "        axes[0].legend()\n",
    "        axes[0].set_yscale('log')\n",
    "        \n",
    "        # Box plot comparison\n",
    "        data_to_plot = [kappa.flatten()[::100], kappa_test.flatten()[::100]]  # Subsample for speed\n",
    "        axes[1].boxplot(data_to_plot, labels=['Training', 'Test (Noisy)'])\n",
    "        axes[1].set_ylabel('κ (Convergence Value)')\n",
    "        axes[1].set_title('Distribution Box Plot Comparison')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Per-sample mean comparison\n",
    "        if kappa.shape[0] > 0 and kappa_test.shape[0] > 0:\n",
    "            train_sample_means = np.mean(kappa, axis=(1, 2))\n",
    "            test_sample_means = np.mean(kappa_test, axis=(1, 2))\n",
    "            \n",
    "            fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "            ax.hist(train_sample_means, bins=30, alpha=0.6, label='Training', \n",
    "                   edgecolor='black')\n",
    "            ax.hist(test_sample_means, bins=30, alpha=0.6, label='Test (Noisy)', \n",
    "                   edgecolor='black')\n",
    "            ax.set_xlabel('Mean κ per Sample')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.set_title('Per-Sample Mean Comparison: Training vs Test')\n",
    "            ax.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"Both training and test data needed for comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac57f9",
   "metadata": {},
   "source": [
    "## 8. Compare Training and Test Set Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample test maps\n",
    "if kappa_test is not None:\n",
    "    if len(kappa_test.shape) == 3:\n",
    "        n_samples = min(4, kappa_test.shape[0])\n",
    "        fig, axes = plt.subplots(1, n_samples, figsize=(16, 4))\n",
    "        if n_samples == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            im = axes[i].imshow(kappa_test[i], cmap='RdBu_r', aspect='auto')\n",
    "            axes[i].set_title(f'Test Sample {i+1}', fontsize=11)\n",
    "            axes[i].set_xlabel('Width')\n",
    "            axes[i].set_ylabel('Height')\n",
    "            plt.colorbar(im, ax=axes[i], label='κ')\n",
    "        \n",
    "        plt.suptitle('Sample Test Convergence Maps (Noisy)', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    elif len(kappa_test.shape) == 2:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "        im = ax.imshow(kappa_test, cmap='RdBu_r', aspect='auto')\n",
    "        ax.set_title('Test Convergence Map (Noisy)', fontsize=14)\n",
    "        ax.set_xlabel('Width (pixels)')\n",
    "        ax.set_ylabel('Height (pixels)')\n",
    "        plt.colorbar(im, ax=ax, label='κ (convergence)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No test data to visualize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load noisy test data\n",
    "if os.path.exists(kappa_noisy_test_file):\n",
    "    kappa_test = np.load(kappa_noisy_test_file)\n",
    "    print(\"Test data (noisy) loaded successfully!\")\n",
    "    print(f\"  Shape: {kappa_test.shape}\")\n",
    "    print(f\"  Data type: {kappa_test.dtype}\")\n",
    "    print(f\"  Memory usage: {kappa_test.nbytes / (1024**2):.2f} MB\")\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  Min: {np.min(kappa_test):.6f}\")\n",
    "    print(f\"  Max: {np.max(kappa_test):.6f}\")\n",
    "    print(f\"  Mean: {np.mean(kappa_test):.6f}\")\n",
    "    print(f\"  Std: {np.std(kappa_test):.6f}\")\n",
    "    print(f\"  Contains NaN: {np.any(np.isnan(kappa_test))}\")\n",
    "    print(f\"  Contains Inf: {np.any(np.isinf(kappa_test))}\")\n",
    "else:\n",
    "    print(\"Test data file not found!\")\n",
    "    kappa_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d38cd5f",
   "metadata": {},
   "source": [
    "## 7. Load and Explore Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kappa is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"CONVERGENCE MAP STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if len(kappa.shape) == 3:\n",
    "        n_samples = kappa.shape[0]\n",
    "        print(f\"\\nNumber of samples: {n_samples}\")\n",
    "        print(f\"Image dimensions: {kappa.shape[1]} × {kappa.shape[2]}\")\n",
    "        \n",
    "        # Compute statistics for each sample\n",
    "        sample_means = np.mean(kappa, axis=(1, 2))\n",
    "        sample_stds = np.std(kappa, axis=(1, 2))\n",
    "        sample_skewness = stats.skew(kappa.reshape(n_samples, -1), axis=1)\n",
    "        sample_kurtosis = stats.kurtosis(kappa.reshape(n_samples, -1), axis=1)\n",
    "        \n",
    "        print(f\"\\nPer-Sample Statistics (across {n_samples} samples):\")\n",
    "        print(f\"  Mean values:\")\n",
    "        print(f\"    Mean: {np.mean(sample_means):.6f}\")\n",
    "        print(f\"    Std:  {np.std(sample_means):.6f}\")\n",
    "        print(f\"    Range: [{np.min(sample_means):.6f}, {np.max(sample_means):.6f}]\")\n",
    "        \n",
    "        print(f\"\\n  Standard deviations:\")\n",
    "        print(f\"    Mean: {np.mean(sample_stds):.6f}\")\n",
    "        print(f\"    Std:  {np.std(sample_stds):.6f}\")\n",
    "        print(f\"    Range: [{np.min(sample_stds):.6f}, {np.max(sample_stds):.6f}]\")\n",
    "        \n",
    "        print(f\"\\n  Skewness:\")\n",
    "        print(f\"    Mean: {np.mean(sample_skewness):.6f}\")\n",
    "        print(f\"    Std:  {np.std(sample_skewness):.6f}\")\n",
    "        \n",
    "        print(f\"\\n  Kurtosis:\")\n",
    "        print(f\"    Mean: {np.mean(sample_kurtosis):.6f}\")\n",
    "        print(f\"    Std:  {np.std(sample_kurtosis):.6f}\")\n",
    "        \n",
    "        # Visualize distributions\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        axes[0, 0].hist(sample_means, bins=30, alpha=0.7, edgecolor='black')\n",
    "        axes[0, 0].set_xlabel('Mean κ per Sample')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "        axes[0, 0].set_title('Distribution of Sample Means')\n",
    "        \n",
    "        axes[0, 1].hist(sample_stds, bins=30, alpha=0.7, edgecolor='black', color='orange')\n",
    "        axes[0, 1].set_xlabel('Std Dev κ per Sample')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        axes[0, 1].set_title('Distribution of Sample Standard Deviations')\n",
    "        \n",
    "        axes[1, 0].hist(sample_skewness, bins=30, alpha=0.7, edgecolor='black', color='green')\n",
    "        axes[1, 0].set_xlabel('Skewness per Sample')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        axes[1, 0].set_title('Distribution of Sample Skewness')\n",
    "        \n",
    "        axes[1, 1].hist(sample_kurtosis, bins=30, alpha=0.7, edgecolor='black', color='red')\n",
    "        axes[1, 1].set_xlabel('Kurtosis per Sample')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('Distribution of Sample Kurtosis')\n",
    "        \n",
    "        plt.suptitle('Statistical Properties of Convergence Maps', fontsize=15)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Pixel value distribution (pooled across all samples)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "        ax.hist(kappa.flatten(), bins=100, alpha=0.7, edgecolor='black', log=True)\n",
    "        ax.set_xlabel('κ (Convergence Value)')\n",
    "        ax.set_ylabel('Frequency (log scale)')\n",
    "        ax.set_title('Overall Pixel Value Distribution (All Samples)')\n",
    "        ax.axvline(0, color='red', linestyle='--', label='Zero')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif len(kappa.shape) == 2:\n",
    "        # Single map statistics\n",
    "        print(f\"\\nImage dimensions: {kappa.shape[0]} × {kappa.shape[1]}\")\n",
    "        print(f\"Total pixels: {kappa.size}\")\n",
    "        \n",
    "        print(f\"\\nStatistics:\")\n",
    "        print(f\"  Mean:     {np.mean(kappa):.6f}\")\n",
    "        print(f\"  Std Dev:  {np.std(kappa):.6f}\")\n",
    "        print(f\"  Skewness: {stats.skew(kappa.flatten()):.6f}\")\n",
    "        print(f\"  Kurtosis: {stats.kurtosis(kappa.flatten()):.6f}\")\n",
    "        \n",
    "        # Pixel value distribution\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "        ax.hist(kappa.flatten(), bins=100, alpha=0.7, edgecolor='black')\n",
    "        ax.set_xlabel('κ (Convergence Value)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Pixel Value Distribution')\n",
    "        ax.axvline(0, color='red', linestyle='--', label='Zero')\n",
    "        ax.axvline(np.mean(kappa), color='green', linestyle='--', label='Mean')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"No convergence maps available for statistical analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f4f7b",
   "metadata": {},
   "source": [
    "## 6. Examine Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dbd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if labels is not None and len(labels.shape) == 2:\n",
    "    # Extract Omega_m and S_8\n",
    "    omega_m = labels[:, 0]\n",
    "    s_8 = labels[:, 1]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Histogram for Omega_m\n",
    "    axes[0, 0].hist(omega_m, bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 0].set_xlabel('Ω_m (Matter Density Fraction)', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 0].set_title('Distribution of Ω_m', fontsize=13)\n",
    "    axes[0, 0].axvline(np.mean(omega_m), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(omega_m):.4f}')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Histogram for S_8\n",
    "    axes[0, 1].hist(s_8, bins=30, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axes[0, 1].set_xlabel('S_8 (Matter Fluctuation Amplitude)', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 1].set_title('Distribution of S_8', fontsize=13)\n",
    "    axes[0, 1].axvline(np.mean(s_8), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(s_8):.4f}')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Scatter plot: Omega_m vs S_8\n",
    "    scatter = axes[1, 0].scatter(omega_m, s_8, alpha=0.6, s=20, c=range(len(omega_m)), \n",
    "                                 cmap='viridis')\n",
    "    axes[1, 0].set_xlabel('Ω_m', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('S_8', fontsize=12)\n",
    "    axes[1, 0].set_title('Joint Distribution: Ω_m vs S_8', fontsize=13)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=axes[1, 0], label='Sample Index')\n",
    "    \n",
    "    # 2D histogram / density plot\n",
    "    axes[1, 1].hist2d(omega_m, s_8, bins=20, cmap='YlOrRd')\n",
    "    axes[1, 1].set_xlabel('Ω_m', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('S_8', fontsize=12)\n",
    "    axes[1, 1].set_title('2D Density: Ω_m vs S_8', fontsize=13)\n",
    "    \n",
    "    plt.suptitle('Cosmological Parameter Distributions', fontsize=15, y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COSMOLOGICAL PARAMETER STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nΩ_m (Matter Density Fraction):\")\n",
    "    print(f\"  Mean:       {np.mean(omega_m):.6f}\")\n",
    "    print(f\"  Std Dev:    {np.std(omega_m):.6f}\")\n",
    "    print(f\"  Min:        {np.min(omega_m):.6f}\")\n",
    "    print(f\"  Max:        {np.max(omega_m):.6f}\")\n",
    "    print(f\"  Median:     {np.median(omega_m):.6f}\")\n",
    "    print(f\"  25th %ile:  {np.percentile(omega_m, 25):.6f}\")\n",
    "    print(f\"  75th %ile:  {np.percentile(omega_m, 75):.6f}\")\n",
    "    \n",
    "    print(f\"\\nS_8 (Matter Fluctuation Amplitude):\")\n",
    "    print(f\"  Mean:       {np.mean(s_8):.6f}\")\n",
    "    print(f\"  Std Dev:    {np.std(s_8):.6f}\")\n",
    "    print(f\"  Min:        {np.min(s_8):.6f}\")\n",
    "    print(f\"  Max:        {np.max(s_8):.6f}\")\n",
    "    print(f\"  Median:     {np.median(s_8):.6f}\")\n",
    "    print(f\"  25th %ile:  {np.percentile(s_8, 25):.6f}\")\n",
    "    print(f\"  75th %ile:  {np.percentile(s_8, 75):.6f}\")\n",
    "    \n",
    "    # Correlation\n",
    "    correlation = np.corrcoef(omega_m, s_8)[0, 1]\n",
    "    print(f\"\\nCorrelation (Ω_m, S_8): {correlation:.6f}\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"Labels not available or in unexpected format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2589ef",
   "metadata": {},
   "source": [
    "## 5. Analyze Cosmological Parameter Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kappa is not None:\n",
    "    # Determine the shape and select samples to visualize\n",
    "    if len(kappa.shape) == 3:\n",
    "        # Multiple samples: (n_samples, height, width)\n",
    "        n_samples = min(6, kappa.shape[0])\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            im = axes[i].imshow(kappa[i], cmap='RdBu_r', aspect='auto')\n",
    "            if labels is not None and len(labels.shape) == 2:\n",
    "                axes[i].set_title(f'Sample {i+1}\\nΩ_m={labels[i,0]:.4f}, S_8={labels[i,1]:.4f}', \n",
    "                                fontsize=10)\n",
    "            else:\n",
    "                axes[i].set_title(f'Sample {i+1}', fontsize=10)\n",
    "            axes[i].set_xlabel('Width (pixels)')\n",
    "            axes[i].set_ylabel('Height (pixels)')\n",
    "            plt.colorbar(im, ax=axes[i], label='κ (convergence)')\n",
    "        \n",
    "        plt.suptitle('Sample Weak Lensing Convergence Maps', fontsize=14, y=1.00)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif len(kappa.shape) == 2:\n",
    "        # Single map: (height, width)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "        im = ax.imshow(kappa, cmap='RdBu_r', aspect='auto')\n",
    "        ax.set_title('Weak Lensing Convergence Map', fontsize=14)\n",
    "        ax.set_xlabel('Width (pixels)')\n",
    "        ax.set_ylabel('Height (pixels)')\n",
    "        plt.colorbar(im, ax=ax, label='κ (convergence)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No convergence maps to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f022256f",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Convergence Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mask\n",
    "if os.path.exists(mask_file):\n",
    "    mask = np.load(mask_file)\n",
    "    print(\"Mask loaded successfully!\")\n",
    "    print(f\"  Shape: {mask.shape}\")\n",
    "    print(f\"  Data type: {mask.dtype}\")\n",
    "    print(f\"\\nMask Statistics:\")\n",
    "    print(f\"  Unique values: {np.unique(mask)}\")\n",
    "    if len(mask.shape) == 2:\n",
    "        valid_pixels = np.sum(mask > 0)\n",
    "        total_pixels = mask.shape[0] * mask.shape[1]\n",
    "        print(f\"  Valid pixels: {valid_pixels} ({100*valid_pixels/total_pixels:.2f}%)\")\n",
    "        print(f\"  Total pixels: {total_pixels}\")\n",
    "else:\n",
    "    print(\"Mask file not found!\")\n",
    "    mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f5a88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence maps (kappa) loaded successfully!\n",
      "  Shape: (101, 256, 132019)\n",
      "  Data type: float16\n",
      "  Memory usage: 6510.70 MB\n",
      "\n",
      "Statistics:\n",
      "  Min: -0.120117\n",
      "  Min: -0.120117\n",
      "  Max: 1.766602\n",
      "  Max: 1.766602\n",
      "  Mean: -0.000273\n",
      "  Mean: -0.000273\n",
      "  Std: inf\n",
      "  Std: inf\n",
      "  Contains NaN: False\n",
      "  Contains NaN: False\n",
      "  Contains Inf: False\n",
      "  Contains Inf: False\n"
     ]
    }
   ],
   "source": [
    "# Load convergence maps (kappa)\n",
    "if os.path.exists(kappa_file):\n",
    "    kappa = np.load(kappa_file)\n",
    "    print(\"Convergence maps (kappa) loaded successfully!\")\n",
    "    print(f\"  Shape: {kappa.shape}\")\n",
    "    print(f\"  Data type: {kappa.dtype}\")\n",
    "    print(f\"  Memory usage: {kappa.nbytes / (1024**2):.2f} MB\")\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  Min: {np.min(kappa):.6f}\")\n",
    "    print(f\"  Max: {np.max(kappa):.6f}\")\n",
    "    print(f\"  Mean: {np.mean(kappa):.6f}\")\n",
    "    print(f\"  Std: {np.std(kappa):.6f}\")\n",
    "    print(f\"  Contains NaN: {np.any(np.isnan(kappa))}\")\n",
    "    print(f\"  Contains Inf: {np.any(np.isinf(kappa))}\")\n",
    "else:\n",
    "    print(\"Convergence maps file not found!\")\n",
    "    kappa = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30192d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded successfully!\n",
      "  Shape: (101, 256, 5)\n",
      "  Data type: float64\n",
      "  Number of samples: 101\n",
      "  First 10 values: [[[ 3.00000000e-01  8.00000000e-01  8.30528666e+00  2.45921191e-02\n",
      "    8.80345858e-03]\n",
      "  [ 3.00000000e-01  8.00000000e-01  7.78855672e+00  4.88651170e-03\n",
      "   -1.34586411e-02]\n",
      "  [ 3.00000000e-01  8.00000000e-01  7.50279072e+00  1.50710039e-02\n",
      "   -1.23787020e-03]\n",
      "  ...\n",
      "  [ 3.00000000e-01  8.00000000e-01  7.50599899e+00  2.31751372e-03\n",
      "   -2.48642935e-02]\n",
      "  [ 3.00000000e-01  8.00000000e-01  7.77596020e+00  1.74759659e-02\n",
      "    4.25011182e-03]\n",
      "  [ 3.00000000e-01  8.00000000e-01  8.30893765e+00  1.10575475e-02\n",
      "   -4.33534023e-03]]\n",
      "\n",
      " [[ 1.95000000e-01  9.55216298e-01  8.30528666e+00  2.45921191e-02\n",
      "    8.80345858e-03]\n",
      "  [ 1.95000000e-01  9.55216298e-01  7.78855672e+00  4.88651170e-03\n",
      "   -1.34586411e-02]\n",
      "  [ 1.95000000e-01  9.55216298e-01  7.50279072e+00  1.50710039e-02\n",
      "   -1.23787020e-03]\n",
      "  ...\n",
      "  [ 1.95000000e-01  9.55216298e-01  7.50599899e+00  2.31751372e-03\n",
      "   -2.48642935e-02]\n",
      "  [ 1.95000000e-01  9.55216298e-01  7.77596020e+00  1.74759659e-02\n",
      "    4.25011182e-03]\n",
      "  [ 1.95000000e-01  9.55216298e-01  8.30893765e+00  1.10575475e-02\n",
      "   -4.33534023e-03]]\n",
      "\n",
      " [[ 3.92600000e-01  7.75840248e-01  8.30528666e+00  2.45921191e-02\n",
      "    8.80345858e-03]\n",
      "  [ 3.92600000e-01  7.75840248e-01  7.78855672e+00  4.88651170e-03\n",
      "   -1.34586411e-02]\n",
      "  [ 3.92600000e-01  7.75840248e-01  7.50279072e+00  1.50710039e-02\n",
      "   -1.23787020e-03]\n",
      "  ...\n",
      "  [ 3.92600000e-01  7.75840248e-01  7.50599899e+00  2.31751372e-03\n",
      "   -2.48642935e-02]\n",
      "  [ 3.92600000e-01  7.75840248e-01  7.77596020e+00  1.74759659e-02\n",
      "    4.25011182e-03]\n",
      "  [ 3.92600000e-01  7.75840248e-01  8.30893765e+00  1.10575475e-02\n",
      "   -4.33534023e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.15300000e-01  8.62178828e-01  8.30528666e+00  2.45921191e-02\n",
      "    8.80345858e-03]\n",
      "  [ 3.15300000e-01  8.62178828e-01  7.78855672e+00  4.88651170e-03\n",
      "   -1.34586411e-02]\n",
      "  [ 3.15300000e-01  8.62178828e-01  7.50279072e+00  1.50710039e-02\n",
      "   -1.23787020e-03]\n",
      "  ...\n",
      "  [ 3.15300000e-01  8.62178828e-01  7.50599899e+00  2.31751372e-03\n",
      "   -2.48642935e-02]\n",
      "  [ 3.15300000e-01  8.62178828e-01  7.77596020e+00  1.74759659e-02\n",
      "    4.25011182e-03]\n",
      "  [ 3.15300000e-01  8.62178828e-01  8.30893765e+00  1.10575475e-02\n",
      "   -4.33534023e-03]]\n",
      "\n",
      " [[ 5.39400000e-01  7.00215486e-01  8.30528666e+00  2.45921191e-02\n",
      "    8.80345858e-03]\n",
      "  [ 5.39400000e-01  7.00215486e-01  7.78855672e+00  4.88651170e-03\n",
      "   -1.34586411e-02]\n",
      "  [ 5.39400000e-01  7.00215486e-01  7.50279072e+00  1.50710039e-02\n",
      "   -1.23787020e-03]\n",
      "  ...\n",
      "  [ 5.39400000e-01  7.00215486e-01  7.50599899e+00  2.31751372e-03\n",
      "   -2.48642935e-02]\n",
      "  [ 5.39400000e-01  7.00215486e-01  7.77596020e+00  1.74759659e-02\n",
      "    4.25011182e-03]\n",
      "  [ 5.39400000e-01  7.00215486e-01  8.30893765e+00  1.10575475e-02\n",
      "   -4.33534023e-03]]\n",
      "\n",
      " [[ 5.02400000e-01  8.63933901e-01  8.30528666e+00  2.45921191e-02\n",
      "    8.80345858e-03]\n",
      "  [ 5.02400000e-01  8.63933901e-01  7.78855672e+00  4.88651170e-03\n",
      "   -1.34586411e-02]\n",
      "  [ 5.02400000e-01  8.63933901e-01  7.50279072e+00  1.50710039e-02\n",
      "   -1.23787020e-03]\n",
      "  ...\n",
      "  [ 5.02400000e-01  8.63933901e-01  7.50599899e+00  2.31751372e-03\n",
      "   -2.48642935e-02]\n",
      "  [ 5.02400000e-01  8.63933901e-01  7.77596020e+00  1.74759659e-02\n",
      "    4.25011182e-03]\n",
      "  [ 5.02400000e-01  8.63933901e-01  8.30893765e+00  1.10575475e-02\n",
      "   -4.33534023e-03]]]\n"
     ]
    }
   ],
   "source": [
    "# Load labels\n",
    "if os.path.exists(label_file):\n",
    "    labels = np.load(label_file)\n",
    "    print(\"Labels loaded successfully!\")\n",
    "    print(f\"  Shape: {labels.shape}\")\n",
    "    print(f\"  Data type: {labels.dtype}\")\n",
    "    print(f\"  Number of samples: {labels.shape[0] if len(labels.shape) > 0 else 'N/A'}\")\n",
    "    if len(labels.shape) == 2:\n",
    "        print(f\"  Number of parameters: {labels.shape[1]}\")\n",
    "        print(f\"\\nFirst 5 samples:\")\n",
    "        print(labels[:5])\n",
    "    else:\n",
    "        print(f\"  First 10 values: {labels[:10]}\")\n",
    "else:\n",
    "    print(\"Labels file not found!\")\n",
    "    labels = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c35d6",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ea3e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Configuration:\n",
      "  Image Dimensions: 1424 × 176 pixels\n",
      "  Resolution: 2 arcmin/pixel\n",
      "  Cosmological Models: 101\n",
      "\n",
      "File Availability:\n",
      "  Labels: ✓ Found\n",
      "    Size: 0.99 MB\n",
      "  Kappa (convergence maps): ✓ Found\n",
      "    Size: 6510.70 MB\n",
      "  Kappa Noisy Test: ✓ Found\n",
      "    Size: 1007.23 MB\n",
      "  Mask: ✓ Found\n",
      "    Size: 0.24 MB\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "data_dir = r'c:\\ML\\Challenges\\NeurIPS_2025'\n",
    "\n",
    "# File paths\n",
    "label_file = os.path.join(data_dir, 'label.npy')\n",
    "kappa_file = os.path.join(data_dir, 'WIDE12H_bin2_2arcmin_kappa.npy')\n",
    "kappa_noisy_test_file = os.path.join(data_dir, 'WIDE12H_bin2_2arcmin_kappa_noisy_test.npy')\n",
    "mask_file = os.path.join(data_dir, 'WIDE12H_bin2_2arcmin_mask.npy')\n",
    "\n",
    "# Configuration\n",
    "IMAGE_HEIGHT = 1424\n",
    "IMAGE_WIDTH = 176\n",
    "RESOLUTION_ARCMIN = 2\n",
    "NUM_COSMOLOGICAL_MODELS = 101\n",
    "\n",
    "# Check which files exist\n",
    "files_to_check = {\n",
    "    'Labels': label_file,\n",
    "    'Kappa (convergence maps)': kappa_file,\n",
    "    'Kappa Noisy Test': kappa_noisy_test_file,\n",
    "    'Mask': mask_file\n",
    "}\n",
    "\n",
    "print(\"Dataset Configuration:\")\n",
    "print(f\"  Image Dimensions: {IMAGE_HEIGHT} × {IMAGE_WIDTH} pixels\")\n",
    "print(f\"  Resolution: {RESOLUTION_ARCMIN} arcmin/pixel\")\n",
    "print(f\"  Cosmological Models: {NUM_COSMOLOGICAL_MODELS}\")\n",
    "print(\"\\nFile Availability:\")\n",
    "for name, path in files_to_check.items():\n",
    "    exists = os.path.exists(path)\n",
    "    print(f\"  {name}: {'✓ Found' if exists else '✗ Not found'}\")\n",
    "    if exists:\n",
    "        size_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "        print(f\"    Size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7160f2",
   "metadata": {},
   "source": [
    "## 2. Define Data Paths and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14873f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67c997",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b022b98",
   "metadata": {},
   "source": [
    "# NeurIPS 2025 Weak Lensing Challenge - Dataset Analysis\n",
    "\n",
    "This notebook analyzes the weak lensing convergence map dataset from the Hyper Suprime-Cam (HSC) survey simulation for cosmological parameter estimation.\n",
    "\n",
    "## Dataset Overview\n",
    "- **Image Dimensions**: 1424 × 176 pixels\n",
    "- **Resolution**: 2 arcmin per pixel\n",
    "- **Field**: Convergence map of redshift BIN 2 of WIDE12H subfield in HSC Y3\n",
    "- **Cosmological Models**: 101 different spatially-flat ΛCDM models\n",
    "- **Target Parameters**: Ω_m (matter density fraction) and S_8 (amplitude of matter fluctuations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
